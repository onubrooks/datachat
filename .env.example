# Application Settings
ENVIRONMENT=development
APP_NAME=DataChat
DEBUG=false
API_HOST=0.0.0.0
API_PORT=8000
SYNC_WATCHER_ENABLED=true
# Env precedence: default uses .env values over shell env.
# Set DATA_CHAT_ENV_SOURCE=system to force system env priority.

# LLM Provider Configuration
# Provider selection: openai, anthropic, google, local
LLM_DEFAULT_PROVIDER=openai
# LLM_CLASSIFIER_PROVIDER=openai  # Optional: override for ClassifierAgent
# LLM_SQL_PROVIDER=openai         # Optional: override for SQLAgent
# LLM_SQL_FORMATTER_MODEL=gemini-2.5-flash-lite # Optional: model override for SQL JSON formatting fallback
# LLM_FALLBACK_PROVIDER=anthropic # Optional: fallback if primary fails

# OpenAI Configuration
LLM_OPENAI_API_KEY=sk-your-key-here
LLM_OPENAI_MODEL=gpt-4o
LLM_OPENAI_MODEL_MINI=gpt-4o-mini

# Anthropic (Claude) Configuration
# LLM_ANTHROPIC_API_KEY=sk-ant-your-key-here
# LLM_ANTHROPIC_MODEL=claude-3-5-sonnet-20241022
# LLM_ANTHROPIC_MODEL_MINI=claude-3-5-haiku-20241022

# Google (Gemini) Configuration
# LLM_GOOGLE_API_KEY=your-key-here
# LLM_GOOGLE_MODEL=gemini-1.5-pro
# LLM_GOOGLE_MODEL_MINI=gemini-1.5-flash

# Local Model Configuration (Ollama, vLLM, etc.)
# LLM_LOCAL_BASE_URL=http://localhost:11434
# LLM_LOCAL_MODEL=llama3.1:8b

# Common LLM Settings
LLM_TEMPERATURE=0.0
LLM_MAX_TOKENS=2000
LLM_TIMEOUT=30

# Target Database Configuration (queries)
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/datachat
DATABASE_TYPE=postgresql
# Supported runtime connectors: postgresql, clickhouse, mysql
# Example MySQL URL: mysql://root:password@localhost:3306/datachat
# System Database Configuration (registry/profiling/demo)
SYSTEM_DATABASE_URL=postgresql://postgres:postgres@localhost:5432/datachat
DATABASE_POOL_SIZE=5
DATABASE_MAX_OVERFLOW=10
DATABASE_POOL_TIMEOUT=30
DATABASE_ECHO=false
# Database registry encryption (generate with: python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())")
# DATABASE_CREDENTIALS_KEY=base64_fernet_key_here

# Chroma Vector Store Configuration
CHROMA_PERSIST_DIR=./chroma_data
CHROMA_COLLECTION_NAME=datachat_knowledge
CHROMA_EMBEDDING_MODEL=text-embedding-3-small
CHROMA_CHUNK_SIZE=512
CHROMA_CHUNK_OVERLAP=50
CHROMA_TOP_K=5

# Logging Configuration
LOG_LEVEL=INFO
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s
LOG_DATE_FORMAT=%Y-%m-%d %H:%M:%S
# LOG_FILE=logs/datachat.log  # Uncomment to enable file logging

# Pipeline Performance Controls (optional)
# PIPELINE_SQL_TWO_STAGE_ENABLED=false
# PIPELINE_SQL_TWO_STAGE_CONFIDENCE_THRESHOLD=0.78
# PIPELINE_SQL_FORMATTER_FALLBACK_ENABLED=true
# PIPELINE_SQL_PROMPT_BUDGET_ENABLED=false
# PIPELINE_SQL_PROMPT_MAX_TABLES=80
# PIPELINE_SQL_PROMPT_FOCUS_TABLES=8
# PIPELINE_SQL_PROMPT_MAX_COLUMNS_PER_TABLE=18
# PIPELINE_SQL_PROMPT_MAX_CONTEXT_CHARS=12000
# PIPELINE_SYNTHESIZE_SIMPLE_SQL_ANSWERS=true
# PIPELINE_CLASSIFIER_DEEP_LOW_CONFIDENCE_THRESHOLD=0.6
# PIPELINE_CLASSIFIER_DEEP_MIN_QUERY_LENGTH=1
# PIPELINE_INTENT_LLM_CONFIDENCE_THRESHOLD=0.45
# PIPELINE_CONTEXT_ANSWER_CONFIDENCE_THRESHOLD=0.7
# PIPELINE_SEMANTIC_SQL_CLARIFICATION_CONFIDENCE_THRESHOLD=0.55
# PIPELINE_SQL_TABLE_RESOLVER_ENABLED=true
# PIPELINE_SQL_TABLE_RESOLVER_CONFIDENCE_THRESHOLD=0.55
# PIPELINE_SQL_TABLE_RESOLVER_MAX_TABLES=20
# PIPELINE_VISUALIZATION_PLANNER_ENABLED=true
# PIPELINE_VISUALIZATION_PLANNER_CONFIDENCE_THRESHOLD=0.55
# PIPELINE_VISUALIZATION_PLANNER_MAX_ROWS_SAMPLE=10
# PIPELINE_VISUALIZATION_PLANNER_MAX_COLUMNS_SAMPLE=12
# PIPELINE_VISUALIZATION_PLANNER_TIMEOUT_MS=1500
# PIPELINE_AMBIGUOUS_QUERY_MAX_TOKENS=3
# PIPELINE_SELECTIVE_TOOL_PLANNER_ENABLED=false
# PIPELINE_SCHEMA_SNAPSHOT_CACHE_ENABLED=true
# PIPELINE_SCHEMA_SNAPSHOT_CACHE_TTL_SECONDS=21600
# PIPELINE_SQL_OPERATOR_TEMPLATES_ENABLED=true
# PIPELINE_SQL_OPERATOR_TEMPLATES_MAX=8
# PIPELINE_QUERY_COMPILER_ENABLED=true
# PIPELINE_QUERY_COMPILER_LLM_ENABLED=true
# PIPELINE_QUERY_COMPILER_LLM_MAX_CANDIDATES=10
# PIPELINE_QUERY_COMPILER_CONFIDENCE_THRESHOLD=0.72
# PIPELINE_VISUALIZATION_LLM_ENABLED=true
# PIPELINE_VISUALIZATION_LLM_ROW_SAMPLE=8
