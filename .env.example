# Application Settings
ENVIRONMENT=development
APP_NAME=DataChat
DEBUG=false
API_HOST=0.0.0.0
API_PORT=8000

# LLM Provider Configuration
# Provider selection: openai, anthropic, google, local
LLM_DEFAULT_PROVIDER=openai
# LLM_CLASSIFIER_PROVIDER=openai  # Optional: override for ClassifierAgent
# LLM_SQL_PROVIDER=openai         # Optional: override for SQLAgent
# LLM_FALLBACK_PROVIDER=anthropic # Optional: fallback if primary fails

# OpenAI Configuration
LLM_OPENAI_API_KEY=sk-your-key-here
LLM_OPENAI_MODEL=gpt-4o
LLM_OPENAI_MODEL_MINI=gpt-4o-mini

# Anthropic (Claude) Configuration
# LLM_ANTHROPIC_API_KEY=sk-ant-your-key-here
# LLM_ANTHROPIC_MODEL=claude-3-5-sonnet-20241022
# LLM_ANTHROPIC_MODEL_MINI=claude-3-5-haiku-20241022

# Google (Gemini) Configuration
# LLM_GOOGLE_API_KEY=your-key-here
# LLM_GOOGLE_MODEL=gemini-1.5-pro
# LLM_GOOGLE_MODEL_MINI=gemini-1.5-flash

# Local Model Configuration (Ollama, vLLM, etc.)
# LLM_LOCAL_BASE_URL=http://localhost:11434
# LLM_LOCAL_MODEL=llama3.1:8b

# Common LLM Settings
LLM_TEMPERATURE=0.0
LLM_MAX_TOKENS=2000
LLM_TIMEOUT=30

# Database Configuration
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/datachat
DATABASE_POOL_SIZE=5
DATABASE_MAX_OVERFLOW=10
DATABASE_POOL_TIMEOUT=30
DATABASE_ECHO=false
# Database registry encryption (generate with: python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())")
# DATABASE_CREDENTIALS_KEY=base64_fernet_key_here

# Chroma Vector Store Configuration
CHROMA_PERSIST_DIR=./chroma_data
CHROMA_COLLECTION_NAME=datachat_knowledge
CHROMA_EMBEDDING_MODEL=text-embedding-3-small
CHROMA_CHUNK_SIZE=512
CHROMA_CHUNK_OVERLAP=50
CHROMA_TOP_K=5

# Logging Configuration
LOG_LEVEL=INFO
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s
LOG_DATE_FORMAT=%Y-%m-%d %H:%M:%S
# LOG_FILE=logs/datachat.log  # Uncomment to enable file logging
